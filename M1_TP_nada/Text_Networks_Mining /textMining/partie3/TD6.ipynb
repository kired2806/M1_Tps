{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "workpath=\"/data/jmoreno/Datasets/signalmedia/\"\n",
    "\n",
    "f=gzip.open(workpath+'signalmedia-1k.jsonl.gz','rb')\n",
    "\n",
    "\n",
    "docs=[json.loads(s.decode('utf-8')) for s in f.readlines()]\n",
    "titres=[x['title'] for x in docs]\n",
    "content=[x['content'] for x in docs]\n",
    "print(len(titres))\n",
    "\n",
    "def sentense2cleanTokens(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = \"\".join([x if x.isalpha() else \" \" for x in sent])\n",
    "    sent = \" \".join(sent.split())\n",
    "    return sent\n",
    "\n",
    "\n",
    "cleantitres=[sentense2cleanTokens(x) for x in titres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "onebigline=\" \".join([line for line in cleantitres])\n",
    "bgm = nltk.collocations.BigramAssocMeasures()\n",
    "finder = nltk.collocations.BigramCollocationFinder.from_words(onebigline.split())\n",
    "ignored_words = nltk.corpus.stopwords.words('english')\n",
    "finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)\n",
    "finder.nbest(bgm.raw_freq, 10)\n",
    "finder.nbest(bgm.pmi, 10)\n",
    "finder.nbest(bgm.likelihood_ratio, 10)\n",
    "finder.nbest(bgm.chi_sq, 10)\n",
    "finder.nbest(bgm.dice, 10)\n",
    "finder.nbest(bgm.fisher, 10)\n",
    "finder.nbest(bgm.jaccard, 10)\n",
    "finder.nbest(bgm.mi_like, 10)\n",
    "finder.nbest(bgm.poisson_stirling, 10)\n",
    "finder.nbest(bgm.student_t, 10)\n",
    "scored = finder.score_ngrams(bgm.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aal', 'dryships'), ('abby', 'bishop'), ('abnormal', 'indications'), ('abu', 'dhabi'), ('access', 'pipeline'), ('accessing', 'europeans'), ('accident', 'importing'), ('acquisition', 'completes'), ('active', 'directory'), ('adidas', 'tubular')]\n"
     ]
    }
   ],
   "source": [
    "print(finder.nbest(bgm.pmi, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.53906965, 0.28761008]\n",
      "[0.53906965, 1.0, 0.48752153]\n",
      "[0.28761008, 0.48752153, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "tokens = nlp(u'dog cat banana')\n",
    "\n",
    "for token1 in tokens:\n",
    "    print([token1.similarity(token2) for token2 in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8.70676279e-01   2.25968742e+00  -6.31433249e-01   5.31767130e-01\n",
      "   2.93478549e-01   1.71422410e+00  -3.22116327e+00   8.72992218e-01\n",
      "   1.93997502e+00   2.87031293e+00   2.26860690e+00  -1.70549440e+00\n",
      "   1.75721931e+00   1.00328475e-01  -1.84722948e+00   8.10127616e-01\n",
      "  -2.36641622e+00  -6.74954116e-01  -2.57085586e+00   1.77607036e+00\n",
      "  -1.85285389e-01   1.23867369e+00  -9.75624084e-01   1.93797398e+00\n",
      "   2.00349092e-02  -1.60199952e+00  -5.47065377e-01   1.61460447e+00\n",
      "  -2.17766643e-01  -2.21958590e+00  -7.38539815e-01  -6.19615197e-01\n",
      "  -3.90584767e-01   1.81061625e-02  -5.94443269e-02  -1.39486265e+00\n",
      "   1.60074508e+00  -5.22987843e-01   2.30428696e+00  -1.77107143e+00\n",
      "  -1.88900435e+00  -2.22219491e+00   1.16671133e+00  -2.62894034e+00\n",
      "  -2.51317739e+00  -6.32965326e-01  -2.00493455e+00  -7.31566668e-01\n",
      "  -1.48643851e-01  -1.04217446e+00   3.28766465e+00  -2.02324653e+00\n",
      "  -2.19653678e+00   3.25622559e+00   3.02244991e-01  -2.88570738e+00\n",
      "   3.49860716e+00   3.15575647e+00   1.48300803e+00   7.33343959e-01\n",
      "  -6.78634048e-02   7.45197952e-01   4.10166681e-01   3.41615963e+00\n",
      "  -3.19031525e+00  -1.13197398e+00  -3.10039043e+00  -1.45067930e+00\n",
      "   5.08339882e+00   2.10492516e+00  -1.19491732e+00  -1.98128939e+00\n",
      "  -1.91702235e+00   1.36788106e+00  -2.37439084e+00   6.75349474e-01\n",
      "  -3.38640308e+00   8.08697522e-01  -9.13916349e-01   4.97806978e+00\n",
      "  -2.40037942e+00  -4.78142071e+00  -2.97761321e-01  -1.17393470e+00\n",
      "   1.28757191e+00   6.94582760e-01  -2.84945279e-01  -1.52763224e+00\n",
      "  -8.30122232e-01   2.08240926e-01  -2.00068235e+00   5.76162434e+00\n",
      "  -1.02909577e+00   2.79890513e+00  -2.84601116e+00   6.36399329e-01\n",
      "  -2.58664846e+00  -9.50223744e-01  -5.09983838e-01   1.84629858e-01\n",
      "  -1.77571988e+00   8.80203485e-01  -2.55665541e-01  -2.19170117e+00\n",
      "   7.10785747e-01   2.48096085e+00   6.00362003e-01  -2.11674356e+00\n",
      "  -9.21109080e-01   7.26945400e-02  -1.17962480e-01  -4.20256329e+00\n",
      "  -1.00509405e+00   2.26658177e+00   1.28629649e+00   4.20804119e+00\n",
      "   9.25158560e-01   4.84393311e+00   2.69508433e+00   3.46127331e-01\n",
      "  -3.85461509e-01   1.44419491e+00   2.60944963e-01   1.41462386e+00\n",
      "   4.04686034e-01  -6.77668691e-01   1.84005928e+00  -2.22921872e+00\n",
      "  -4.06652391e-02  -4.67512190e-01  -1.48603320e-03   6.95465505e-03\n",
      "  -2.33619034e-01   5.22386074e-01   2.84444273e-01  -1.15923151e-01\n",
      "   7.28982687e-01   1.22455049e+00   6.42329097e-01   1.72698319e-01\n",
      "   2.37713054e-01  -2.45614767e-01  -5.31564236e-01   2.80810833e-01\n",
      "  -3.67165625e-01   1.08276904e+00   1.30272877e+00  -1.78961456e-02\n",
      "   1.58501223e-01  -1.53160602e-01   4.31687385e-01   5.04580736e-01\n",
      "  -1.80815101e-01  -6.07171953e-01   2.33618945e-01  -4.76103902e-01\n",
      "   3.17476839e-01   6.07749522e-02  -3.01800549e-01   1.86645195e-01\n",
      "  -2.40718156e-01   9.51831490e-02   1.72668725e-01  -5.08097768e-01\n",
      "   3.78385246e-01  -2.01166272e-01   2.76784122e-01  -1.63674489e-01\n",
      "  -2.74965256e-01   1.27325094e+00  -3.66869509e-01  -6.93550467e-01\n",
      "   1.95240870e-01   3.60833943e-01  -2.95570433e-01   1.23157158e-01\n",
      "   1.22458473e-01  -4.77824748e-01  -7.17128336e-01  -5.46422482e-01\n",
      "  -6.93517506e-01  -1.01627186e-01  -1.84363306e-01  -5.38910031e-01\n",
      "   1.04846478e+00  -4.06310320e-01   1.01303637e+00   4.06900972e-01\n",
      "   1.19597763e-02   8.11238587e-03  -6.22076154e-01  -1.07789330e-01\n",
      "   3.21342915e-01  -5.73210865e-02  -4.30696942e-02  -3.93690169e-02\n",
      "   3.06534141e-01   4.46396798e-01   4.20492142e-02  -1.33389786e-01\n",
      "  -6.03910744e-01  -1.27840057e-01  -4.00342643e-02   3.08850229e-01\n",
      "   4.10064787e-01   1.16241395e-01   2.33252555e-01   5.03606319e-01\n",
      "   6.77373856e-02   2.01282725e-01  -2.64298230e-01   5.44343412e-01\n",
      "  -2.30995208e-01   3.08135062e-01  -4.22784775e-01   2.55575657e-01\n",
      "   3.31189483e-02  -3.54866683e-01   4.84220326e-01  -5.85271358e-01\n",
      "  -4.20104861e-01  -1.40500993e-01  -2.67978817e-01  -5.74545443e-01\n",
      "   1.21183544e-01  -2.41952956e-01  -9.90165547e-02  -6.40586555e-01\n",
      "  -2.73681521e-01  -4.37585056e-01  -1.93783641e-02   8.56102228e-01\n",
      "   3.58360142e-01  -5.37714720e-01  -6.61365449e-01   5.63704669e-02\n",
      "  -2.76966751e-01   2.16685474e-01  -2.96320617e-01  -6.58174276e-01\n",
      "   4.13358212e-04  -5.82549453e-01   8.70170772e-01  -1.10104299e+00\n",
      "   1.00363418e-01  -8.17722082e-03  -4.07111287e-01   4.44866717e-01\n",
      "   2.95535803e-01  -7.10227489e-01   1.76620752e-01  -1.90713301e-01\n",
      "   1.01572052e-01   5.02178788e-01   1.53021649e-01   1.01062149e-01\n",
      "  -5.07146716e-01  -3.91342826e-02   1.16600171e-01  -4.33095127e-01\n",
      "  -2.34599590e-01  -4.86286759e-01   1.51597828e-01  -2.63361365e-01\n",
      "  -4.11679536e-01   4.28257436e-02   5.18879890e-01  -2.69072056e-02\n",
      "  -2.52550468e-02  -2.86169916e-01  -4.05630589e-01   8.76508892e-01\n",
      "  -4.14750457e-01  -6.94889784e-01  -1.43930554e-01  -4.42611843e-01\n",
      "  -4.15173918e-02  -1.65128976e-01   7.30870843e-01  -7.73141503e-01\n",
      "  -8.94797385e-01  -8.06587189e-03  -3.32444906e-01   7.14596629e-01\n",
      "   4.97321934e-01   4.37572062e-01  -1.63666934e-01  -3.96017969e-01\n",
      "  -1.15766339e-01   1.90385520e-01  -1.40671045e-01  -1.27407953e-01\n",
      "  -2.87741125e-02   1.24680030e+00  -5.69144152e-02  -6.23616040e-01\n",
      "   3.55026424e-01  -3.07343125e-01  -1.43173188e-01  -7.04668462e-01\n",
      "   1.15118288e-01  -4.79473174e-01  -3.06571007e-01  -7.34606266e-01\n",
      "   6.35308683e-01  -2.00366959e-01  -1.28522515e-03  -4.58063185e-01\n",
      "   5.81227124e-01   7.76143670e-01  -7.04051077e-01   5.24202466e-01\n",
      "  -7.45324373e-01   2.07849413e-01   1.19614697e+00   1.60454571e-01\n",
      "   2.52509981e-01   1.08977509e+00  -5.05234838e-01   4.17667627e-01\n",
      "   6.62335515e-01   9.39823687e-01  -2.06791788e-01   3.61841202e-01\n",
      "  -1.41515136e-01   9.32005048e-03  -6.51810706e-01   5.70473261e-03\n",
      "   7.80452341e-02  -2.36647427e-01   9.54242885e-01   1.60301045e-01\n",
      "   7.97009096e-03   6.48415387e-01  -1.92149878e-01   5.31456769e-01\n",
      "  -3.16610813e-01   7.20902830e-02  -1.55508816e-01  -1.21347934e-01\n",
      "  -2.87318230e-01   4.45694700e-02   7.66073465e-02   6.87306374e-03\n",
      "  -1.36181027e-01   2.23133445e-01  -1.90856531e-01   5.62601686e-01\n",
      "   5.96076787e-01  -3.78683686e-01  -2.36844257e-01   2.21053034e-01\n",
      "  -3.34622175e-01  -3.67992520e-02  -7.81274736e-02  -8.11135471e-01\n",
      "  -4.14536476e-01   2.77438879e-01  -8.62041175e-01  -7.64657497e-01\n",
      "   6.19463027e-02   4.10663098e-01   1.10023275e-01   1.57898784e-01\n",
      "  -8.87556374e-01   9.46275890e-01  -3.14768434e-01   7.42281556e-01\n",
      "   2.96338439e-01   7.75381178e-02  -7.64443636e-01   2.83101588e-01\n",
      "   7.28584900e-02  -7.03643560e-01   7.48623908e-03   1.15519941e+00\n",
      "  -5.08892059e-01   9.92311016e-02   7.33281612e-01  -1.39759123e-01\n",
      "  -4.54664558e-01  -3.06941181e-01   2.28667825e-01  -2.40245014e-01]\n"
     ]
    }
   ],
   "source": [
    "dog=tokens[0]\n",
    "print(dog.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Loading IMDB data...\n",
      "Using 2000 examples (1600 training, 400 evaluation)\n",
      "(\"This is absolutely the dumbest movie I've ever seen. What a waste of a splendid cast. That's James Cromwell as the ignoramus playing deputy. I could go on and on, but I would obviously be spending more time on this review than anybody ever did on the script. The only thing this movie is about is us vs. them and how to revel in profane slapstick beyond any reasonable human being's tolerance. This is one of the 10 worst movies I have ever seen -- and I LOVE James Garner.\", \"but I want to say I cannot agree more with Moira.\\n\\n\\n\\nWhat a wonderful film.\\n\\n\\n\\nI was thinking about it just this morning, wanting to give advice to some dopey sod who'd lost money on his debit card through fraud, and wanted to say 'Keep thy money in thine pocket' and realised I was talking like James Mason.\\n\\n\\n\\nEven tho he didn't say those words, I still think he would! I've never forgotten 'Are ye carrying?' in his reconciliation with his son, Hywel Bennet: 'Always have money in thine pocket!' Good advice.\\n\\n\\n\\nNot enough kids have fathers with such unforgiving but well-meant attitudes any more. Or any father at all.\\n\\n\\n\\nIt would be a good thing for us to reinstate 'thee', 'thy' and 'thine' in our language to show we care. It is only the same as 'tutoyer' in French or 'du' in German.\\n\\n\\n\\nAddendum: I just realised that a lot of my remarks were about James Mason in The Family Way!\\n\\n\\n\\nI think it's because I mixed up Susan George with Hayley Mills. Well, easy mistake.\\n\\n\\n\\nI stand by the comments tho'.\\n\\n\\n\\nAnd Spring and Port Wine is so very similar to The Family Way.\\n\\n\\n\\nWhen you took a girlfriend to the pictures in those days, you really had something to say and talk about afterwards, something that affected your knowledge of the world and your personal development.\\n\\n\\n\\nTheatrical experiences are almost real, and they are important in helping young people to grow up.\\n\\n\\n\\nIt doesn't happen now, I think, that teenagers can just go to the pics like we did.\", 'IQ is a cute romantic comedy featuring two great actors that seem to click well on screen. Plot is a typical guy wrong for girl, guy gets girl format, but makes the solid point that one must love with the heart and not the the mind. Addition of Albert Einstein and his band of geniuses provides excellent comic relief. Overall, a good movie. Not great, but good', 'Why does this movie fall WELL below standards? Ultimately, the answer lies in the poor, humourless script. A slim/average looking Travolta (looking rather dapper in black I must say, even with a HUGE mullet) and Gross both act very well as two young-ish \\'slick-dressed\\' but nevertheless dimwitted New Yorkers eager to open their own nightclub. Other than that, the rest of the film is just boring to watch. It is SO dull that it\\'s really not worth knowing what happens in the film\\'s climax on any level. Kelly Preston obviously exudes sex appeal and the sexually charged dance with her husband-to-be Travolta is one of the film\\'s few pleasures. Charles Martin Smith is quite fun to watch as struggling KGB honcho \"Bob Smith\". Personally, I think the movie would have been better if the plot was altered a little so that the settings did not change from NY to \\'Indian Springs, Nebraska\\' (which is in the former Soviet Union?)--you\\'ll understand if you see the movie... Apparently, this movie was filmed in 1986 ready for a 1987 release. I guess Paramount stalled on releasing the movie until January 1989 because of the unbelievable plot. It was reported they deemed it \"unreleasable\". Nevertheless, this $6,000,000 film garnered a little over an embarrassing $163,000 in revenue as it was released only BRIEFLY in places like Texas and Colorado before heading straight-to-video. This is testament to the overall BAD quality of this movie.', \"Disney (and the wonderful folks at PIXAR of course) offer a nice, humourous story combined with the best of computer animation. I admit that maybe the 'faces' of the bugs were a little more static than in 'Antz' and they only had four legs (in 'Antz' six...). But backgrounds were superb and animation was breathtaking. But let this be a lesson: it was not the computer who made it such a success : it was the man behind the machine, who added the nice little twists, which I missed in 'Antz'. Some highlights were of course the 'bloopers' at the end (So keep watching at the end, it's worth it!), which were highly amusing and original. The line 'Filmed entirely on location' was intended for the more attentive viewer.\") [{'POSITIVE': False}, {'POSITIVE': True}, {'POSITIVE': True}, {'POSITIVE': False}, {'POSITIVE': True}]\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "84.308\t0.678\t0.882\t0.767\n",
      "36.742\t0.786\t0.868\t0.825\n",
      "15.228\t0.825\t0.855\t0.839\n",
      "This movie sucked {'POSITIVE': 0.3177388608455658}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf8\n",
    "\"\"\"Train a multi-label convolutional neural network text classifier on the\n",
    "IMDB dataset, using the TextCategorizer component. The dataset will be loaded\n",
    "automatically via Thinc's built-in dataset loader. The model is added to\n",
    "spacy.pipeline, and predictions are available via `doc.cats`. For more details,\n",
    "see the documentation:\n",
    "* Training: https://spacy.io/usage/training\n",
    "\n",
    "Compatible with: spaCy v2.0.0+\n",
    "\"\"\"\n",
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import thinc.extra.datasets\n",
    "\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "\n",
    "def main(model=None, output_dir=None, n_iter=3, n_texts=2000):\n",
    "    nlp = spacy.blank('en')  # create blank Language class\n",
    "    print(\"Created blank 'en' model\")\n",
    "\n",
    "    # add the text classifier to the pipeline if it doesn't exist\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    textcat = nlp.create_pipe('textcat')\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "    \n",
    "    # add label to text classifier\n",
    "    textcat.add_label('POSITIVE')\n",
    "\n",
    "    # load the IMDB dataset\n",
    "    print(\"Loading IMDB data...\")\n",
    "    (train_texts, train_cats), (dev_texts, dev_cats) = load_data(limit=n_texts)\n",
    "    print(\"Using {} examples ({} training, {} evaluation)\"\n",
    "          .format(n_texts, len(train_texts), len(dev_texts)))\n",
    "    train_data = list(zip(train_texts,\n",
    "                          [{'cats': cats} for cats in train_cats]))\n",
    "    print(train_texts[:5],train_cats[:5])\n",
    "    optimizer = nlp.begin_training()\n",
    "    print(\"Training the model...\")\n",
    "    print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n",
    "    for i in range(n_iter):\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\n",
    "                           losses=losses)\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                # evaluate on the dev data split off in load_data()\n",
    "                scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "            print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  # print a simple table\n",
    "                  .format(losses['textcat'], scores['textcat_p'],\n",
    "                          scores['textcat_r'], scores['textcat_f']))\n",
    "\n",
    "    # test the trained model\n",
    "    test_text = \"This movie sucked\"\n",
    "    doc = nlp(test_text)\n",
    "    print(test_text, doc.cats)\n",
    "\n",
    "\n",
    "def load_data(limit=0, split=0.8):\n",
    "    \"\"\"Load data from the IMDB dataset.\"\"\"\n",
    "    # Partition off part of the train data for evaluation\n",
    "    train_data, _ = thinc.extra.datasets.imdb()\n",
    "    random.shuffle(train_data)\n",
    "    train_data = train_data[-limit:]\n",
    "    texts, labels = zip(*train_data)\n",
    "    cats = [{'POSITIVE': bool(y)} for y in labels]\n",
    "    split = int(len(train_data) * split)\n",
    "    return (texts[:split], cats[:split]), (texts[split:], cats[split:])\n",
    "\n",
    "\n",
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 1e-8  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 1e-8  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDB data...\n",
      "Using 2000 examples (1600 training, 400 evaluation)\n",
      "('My mother worked with Dennis L. Raider for eleven years, not to mention shared an office with him. When it was announced he was BTK, she was shocked. The whole day was just her telling stories about how she never would have seen him as the Wichita Killer. I\\'ve heard her re-tell them many times. I\\'ve inquired her about a lot of things, and gone to all the interviews that she was asked to go to. I\\'ve read the entire book written about Raider, Wichita is my hometown and I was surprised that such a thing could happen in Kansas.\\n\\n\\n\\nThere was another BTK movie on TV not too long ago, and I thought this one would have been better at portraying Dennis\\' killings, maybe even have some intelligent touches to his motives.\\n\\n\\n\\nI\\'m going to be very blunt with the flaws in this movie. This is based on my mom\\'s portrayal of him, all my readings on him, and the video tapes I\\'ve seen of him talking.\\n\\n\\n\\nFirst of all, the camera angles were horrible. It looked as though it had been shot on a home video camera. The acting was terrible and I couldn\\'t even bear to watch it.\\n\\n\\n\\nDennis Raider never had long hair. Dennis Raider was a \"very anal man\" and was a \"follow the rule book\" kind of guy. He wasn\\'t as nice as the movie made him look, he was very polite and abrupt, business like. Same goes for his killings, as far as we all know. If you\\'ve seen his confession in court, you can already guess.\\n\\n\\n\\nAnd as for the obsession with the slaughter house? No. Never have I read or has Dennis Raider confessed to having a problem with animal cruelty or people squishing bugs. In fact, he practiced on cats and dogs for choking methods. Yet through-out the whole movie he was putting animals in his victim\\'s faces and acting like he cared about the well-being of them.\\n\\n\\n\\nDennis Raider never killed the people that he knew, he confessed this, but in the movie in his first killing he tells the lady he knows her also.\\n\\n\\n\\nI really don\\'t even want to go in to this movie, and I\\'m already ranting. This is NOT what you want to watch if you are interested in the actual happenings of BTK. This is NOT what you want to watch if you want a good horror movie. If you want a badly shot half-porno with some slaughter scenes served the side, then this is your kind of movie.', \"I have grown up with Scooby doo all my life, My dad grew up with scooby doo. We have just watched the first episode of the travesty that calls itself Shaggy and Scooby get a clue. What planet are Warner Bros on allowing this shambles to air. The characters could have been drawn better by my younger sister. The story could have been better written by my 3 year old twin cousins (who are Scooby Doo fans too). Scooby and Shaggy just aren't!!!!! if anyone but Casey Kasem does the voice of Shaggy it just isn't gonna work folks!!!! trust me.\\n\\n\\n\\nThis program was disgraceful. What's New Scooby Doo is much better. Why change a winning format. Bin this piece of garbage and go back to the true Scooby\", 'I just read the plot summary and it is the worst one I have ever read. It does not do justice to this incredible movie. For an example of a good summary, read the listing at \"Turner Classic Movies\". Anyway, this was one of my favorite movies as a young child. My sister and I couldn\\'t wait until every April when we could see it on T.V. It is one of the best horse movies of it\\'s time. It is one of those great classics that the whole family can watch. The romance is clean and endearing. The story line is interesting and the songs are great. They don\\'t make movies like this anymore. Good acting and not over the top. Pat Boone and Shirley Jones are at their best, along with many other great character actors.', 'This is one of those movies that I\\'ve seen so many times that I can quote most of it. Some of the lines in this movie are just unbeatable. I particularly enjoy watching him stumble and fall while drunk, go out to the fancy restaurant drunk and the part with the moose.\\n\\n\\n\\nI don\\'t know how many times I have seen this sequence but it\\'s funny every time. From the moment Arthur gets to Susan\\'s Dad\\'s place to the bit with the moose, you pretty much laugh the whole time. I remember watching the out-takes regarding the bit with the moose. It went down just like I\\'d imagined it\\'d be like. They were all laughing so hard it was difficult for them to film it.\\n\\n\\n\\nThe late Sir John Gielgud was a wonderful addition to this. His demeanor, his one-liners and the way he handled Arthur were all equally hilarious. It\\'s always a funny moment when he whacks him over the head with his hat or tells him he\\'s a spoiled little ____. I laugh every time I listen to the \"I\\'m going to have a bath\" and the lines that follow.', \"This is one of those movies that they did too much promoting for. If you watch T.V., then you might as well not watch the movie. Almost all the funny scenes are spoiled in the previews, except one which just happens to be Jennifer Annisten being the funny one. It is typical Jim Carrey humor and it is really funny. Just don't go see this movie expecting to be surprised. All in all, if you like Jim Carrey or comedies this is a must-see, otherwise just watch the previews and you'll be just as satisfied.\") [{'POSITIVE': False}, {'POSITIVE': False}, {'POSITIVE': True}, {'POSITIVE': True}, {'POSITIVE': True}]\n"
     ]
    }
   ],
   "source": [
    "n_texts=2000\n",
    "\n",
    "# load the IMDB dataset\n",
    "print(\"Loading IMDB data...\")\n",
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data(limit=n_texts)\n",
    "print(\"Using {} examples ({} training, {} evaluation)\"\n",
    "       .format(n_texts, len(train_texts), len(dev_texts)))\n",
    "train_data = list(zip(train_texts,\n",
    "                      [{'cats': cats} for cats in train_cats]))\n",
    "print(train_texts[:5],train_cats[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My mother worked with Dennis L. Raider for eleven years, not to mention shared an office with him. When it was announced he was BTK, she was shocked. The whole day was just her telling stories about how she never would have seen him as the Wichita Killer. I've heard her re-tell them many times. I've inquired her about a lot of things, and gone to all the interviews that she was asked to go to. I've read the entire book written about Raider, Wichita is my hometown and I was surprised that such a thing could happen in Kansas.\n",
      "\n",
      "\n",
      "\n",
      "There was another BTK movie on TV not too long ago, and I thought this one would have been better at portraying Dennis' killings, maybe even have some intelligent touches to his motives.\n",
      "\n",
      "\n",
      "\n",
      "I'm going to be very blunt with the flaws in this movie. This is based on my mom's portrayal of him, all my readings on him, and the video tapes I've seen of him talking.\n",
      "\n",
      "\n",
      "\n",
      "First of all, the camera angles were horrible. It looked as though it had been shot on a home video camera. The acting was terrible and I couldn't even bear to watch it.\n",
      "\n",
      "\n",
      "\n",
      "Dennis Raider never had long hair. Dennis Raider was a \"very anal man\" and was a \"follow the rule book\" kind of guy. He wasn't as nice as the movie made him look, he was very polite and abrupt, business like. Same goes for his killings, as far as we all know. If you've seen his confession in court, you can already guess.\n",
      "\n",
      "\n",
      "\n",
      "And as for the obsession with the slaughter house? No. Never have I read or has Dennis Raider confessed to having a problem with animal cruelty or people squishing bugs. In fact, he practiced on cats and dogs for choking methods. Yet through-out the whole movie he was putting animals in his victim's faces and acting like he cared about the well-being of them.\n",
      "\n",
      "\n",
      "\n",
      "Dennis Raider never killed the people that he knew, he confessed this, but in the movie in his first killing he tells the lady he knows her also.\n",
      "\n",
      "\n",
      "\n",
      "I really don't even want to go in to this movie, and I'm already ranting. This is NOT what you want to watch if you are interested in the actual happenings of BTK. This is NOT what you want to watch if you want a good horror movie. If you want a badly shot half-porno with some slaughter scenes served the side, then this is your kind of movie.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "tokens = [nlp(x) for x in train_texts]\n",
    "print(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -7.88929641e-01   2.49472904e+00   1.00183964e-01   5.38341808e+00\n",
      "  -2.34359550e+00  -6.48356974e-03   2.08560324e+00   4.17754292e-01\n",
      "  -2.53991461e+00   1.17190552e+00  -5.45085430e-01   1.99631667e+00\n",
      "   2.20726848e+00  -2.87431192e+00  -9.07552123e-01  -7.13188410e-01\n",
      "   2.00203657e+00   1.94827056e+00   1.38894677e+00  -2.59848163e-02\n",
      "   2.65874267e+00   1.89830577e+00   1.02724814e+00   3.62629080e+00\n",
      "   5.48710227e-01  -8.50266159e-01  -1.53428459e+00   1.15709448e+00\n",
      "   1.81238890e+00   1.45786011e+00   1.91748834e+00   5.52694273e+00\n",
      "   9.55302954e-01   4.26679850e-01   6.33236766e-02   1.09611678e+00\n",
      "   3.92184758e+00   3.99406999e-02  -3.19887996e+00   9.80772257e-01\n",
      "  -1.04980576e+00  -1.30675709e+00  -1.55589318e+00  -1.47749376e+00\n",
      "  -6.66910589e-01  -2.24673295e+00  -2.21372724e-01   1.35512769e+00\n",
      "  -7.36700118e-01  -8.31505537e-01   7.00726628e-01   4.04854965e+00\n",
      "  -1.48289466e+00  -2.10138655e+00  -2.37878847e+00   2.66663766e+00\n",
      "   4.54227656e-01  -1.80881274e+00   9.38413739e-01  -1.77628660e+00\n",
      "   1.25433707e+00   3.30200315e+00   1.42954421e+00  -2.19376469e+00\n",
      "   2.43364900e-01  -4.60227680e+00   3.57585073e-01  -8.46702337e-01\n",
      "  -1.46700501e+00  -8.38224292e-02  -4.41152751e-01  -1.54284298e+00\n",
      "   6.92003369e-01  -4.58570778e-01   3.17809296e+00  -4.26946163e+00\n",
      "  -4.45741534e-01  -1.41699803e+00   1.34579754e+00   1.34134337e-01\n",
      "  -2.04914427e+00  -6.55667365e-01  -3.01823616e-01  -1.04717004e+00\n",
      "  -3.85887980e-01  -1.04879177e+00  -1.41488445e+00  -9.06252801e-01\n",
      "   3.98901910e-01  -4.43920523e-01  -1.94458187e-01   9.16898012e-01\n",
      "   4.81677198e+00  -6.89957559e-01   7.90677309e-01   4.72094029e-01\n",
      "   2.02650785e+00  -9.11064863e-01   4.56878567e+00   4.60604250e-01\n",
      "  -3.25523567e+00  -3.20754528e+00   9.15774167e-01  -1.77286077e+00\n",
      "  -1.58127058e+00  -1.71617150e-01  -3.10280979e-01  -2.25237632e+00\n",
      "  -4.71793652e-01   3.29561949e+00  -1.00765920e+00   2.84245610e-01\n",
      "  -1.36093867e+00  -5.00176072e-01   5.12285280e+00   3.68621159e+00\n",
      "  -1.87288535e+00  -3.15411568e+00  -6.04126692e-01   1.80639493e+00\n",
      "  -1.80512428e+00  -1.82346344e+00   1.27830791e+00  -1.65753531e+00\n",
      "  -4.50641727e+00  -6.11706376e-01  -1.22664094e+00  -2.95348310e+00\n",
      "  -6.63783491e-01  -1.03373897e+00   3.36728960e-01  -1.91608623e-01\n",
      "  -3.46126229e-01  -5.24407253e-02  -5.75113654e-01   9.42328513e-01\n",
      "   9.23953503e-02   1.32008052e+00   2.47146934e-01   2.79666007e-01\n",
      "   1.75099134e+00  -7.15950787e-01  -1.55945152e-01   1.38439333e+00\n",
      "  -8.18457425e-01   1.03957975e+00  -3.53255123e-01  -3.42536867e-01\n",
      "   3.65446210e-01   7.65424013e-01  -1.07210204e-01  -3.39525282e-01\n",
      "   5.57163000e-01  -7.00578988e-01   1.71899945e-01   3.39779258e-01\n",
      "   1.14831328e+00  -9.80355918e-01   2.21027106e-01   1.59582645e-01\n",
      "  -1.14158320e+00  -6.89276338e-01   4.16219234e-03  -4.19257939e-01\n",
      "   6.44571483e-02  -6.05131626e-01   6.12131953e-01   4.01356518e-01\n",
      "  -1.30817160e-01   5.64305305e-01  -3.89677018e-01   7.79458940e-01\n",
      "   9.43787932e-01   7.45683074e-01   1.57794547e+00  -2.01589078e-01\n",
      "  -5.76835871e-01  -6.02275074e-01  -1.05129838e+00  -1.60745800e-01\n",
      "  -4.13601965e-01  -4.00965810e-01   1.02595985e-01  -6.63454652e-01\n",
      "   7.53631294e-02   2.49172896e-01   4.10344362e-01   3.25713232e-02\n",
      "  -5.45857728e-01  -8.68224621e-01  -8.99040699e-01   1.66052377e+00\n",
      "  -3.60463083e-01  -8.19167420e-02   8.43106031e-01  -1.00759351e+00\n",
      "   3.87630850e-01   7.35611439e-01  -9.25277710e-01  -2.37586349e-01\n",
      "  -5.14223725e-02   2.44700059e-01  -4.57260907e-01  -1.35195255e-01\n",
      "   1.82702392e-01  -4.26497847e-01   3.32911134e-01  -5.58183610e-01\n",
      "   1.87208116e-01  -7.58296132e-01  -6.70522094e-01  -2.08133608e-01\n",
      "   4.09229457e-01   1.79346383e-01   7.01388597e-01   4.73469496e-02\n",
      "  -1.60584831e+00   5.58503866e-02  -5.09823203e-01  -9.57055926e-01\n",
      "  -2.72343189e-01  -1.49057353e+00   4.04775918e-01   8.31242025e-01\n",
      "   7.77877927e-01   1.16176188e-01  -4.78849441e-01  -2.45613486e-01\n",
      "  -3.41891229e-01   4.62829858e-01  -4.61473316e-01   6.06905580e-01\n",
      "   1.11636448e+00   7.28966117e-01   5.73074520e-01   8.09657723e-02\n",
      "   5.29305756e-01   6.16769716e-02   7.35339820e-02   1.39512986e-01\n",
      "   1.49975091e-01  -1.34705067e+00  -2.93361783e-01   9.08439159e-02\n",
      "   8.75917077e-01  -3.80356833e-02   3.31359655e-01  -4.70974833e-01\n",
      "  -4.82682139e-01   3.86004061e-01  -4.36206996e-01   6.52485013e-01\n",
      "   3.74536216e-01  -2.87578404e-02   1.34270042e-01   1.08306110e-03\n",
      "   1.75118834e-01  -7.54412711e-01  -3.80773813e-01   6.36314601e-02\n",
      "  -3.93083274e-01  -6.95526123e-01   2.78477818e-01  -3.47882032e-01\n",
      "   4.31879401e-01   2.39643529e-01  -8.88308734e-02  -1.68736801e-01\n",
      "  -8.43893945e-01  -6.32354245e-02   8.03064629e-02  -4.95158702e-01\n",
      "   3.26804519e-01   4.91575718e-01  -3.00107181e-01  -6.52090460e-03\n",
      "   5.22664636e-02  -5.71828783e-01   1.37818789e+00  -1.63566351e-01\n",
      "  -2.90489495e-01   1.34179342e+00  -4.86028671e-01  -8.81494135e-02\n",
      "   1.45040840e-01   5.14002919e-01  -2.45873481e-01  -1.24493212e-01\n",
      "  -1.05481684e-01   6.44491136e-01  -5.25438845e-01  -4.14570034e-01\n",
      "   7.46756434e-01  -1.10402659e-01   2.58690387e-01   5.48097342e-02\n",
      "   4.37233746e-01   6.40882075e-01  -8.26125443e-02  -2.08319530e-01\n",
      "  -1.34440035e-01   3.18715721e-02  -2.66712487e-01   8.68037716e-03\n",
      "   3.65437776e-01  -2.08982736e-01   7.20443010e-01  -1.12303424e+00\n",
      "   8.80874470e-02   1.13828361e+00  -4.46617901e-01   5.61891377e-01\n",
      "   4.17584598e-01   5.31563997e-01   2.85837799e-01  -5.21527171e-01\n",
      "  -2.09195927e-01   7.96773851e-01  -8.73770297e-01  -4.65116203e-01\n",
      "  -1.68688595e-02   3.07431519e-01  -1.78040490e-01   7.47173309e-01\n",
      "  -3.28288138e-01  -1.04604393e-01   3.60797644e-01  -1.67078048e-01\n",
      "  -1.62084550e-01   5.17308712e-03  -3.12848300e-01   5.48935950e-01\n",
      "  -4.33020562e-01   5.03259897e-01  -2.47929633e-01  -4.41442013e-01\n",
      "  -1.68000460e-02  -2.41428316e-01  -1.51006013e-01  -1.23633862e+00\n",
      "  -3.73468995e-01   1.70137480e-01   1.65202245e-01   4.21413630e-02\n",
      "  -1.63886964e-01   4.67941225e-01   6.32426858e-01   6.26227021e-01\n",
      "  -7.83452272e-01  -5.61225712e-01  -8.31392482e-02   1.82012931e-01\n",
      "  -4.25755918e-01  -5.37520826e-01   4.64523047e-01   6.80640638e-01\n",
      "   1.41487122e-01  -3.77934992e-01  -3.56292188e-01  -3.12584758e-01\n",
      "  -4.94398415e-01  -5.53233624e-01  -1.37371153e-01  -5.58888853e-01\n",
      "  -8.32812488e-01   1.04486167e-01  -1.08972371e-01   4.77417082e-01\n",
      "  -3.63316298e-01   1.26642123e-01   3.05701554e-01  -7.50937164e-02\n",
      "  -2.96551764e-01  -5.93589127e-01  -2.30204865e-01  -3.31102073e-01\n",
      "  -3.96901280e-01   7.77644932e-01   3.44682455e-01   2.72818357e-02\n",
      "  -6.31824210e-02   6.21582687e-01   7.04342663e-01   1.07806504e-01]\n"
     ]
    }
   ],
   "source": [
    "print(tokens[0][0].vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=[]\n",
    "for x in tokens:\n",
    "    vectors.append([w.vector/w.vector_norm for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
