{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2: Ecrire comme votre auteur favori\n",
    "\n",
    "Nous allons d'abord commencer par la problématique de prédiction de mots. L'idée est d'utiliser un livre pour apprendre à la machine dans quel ordre les mots ont le plus de chance d'apparaitre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Téléchargement de livres depuis Project Gutenberg (https://www.gutenberg.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d4590078ff40d0a36184118fa0ffb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='bookTitle', options=(\"Alice's Adventures in Wonderland\", 'The Comp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "#List of books along with their identifier on Project Gutenberg\n",
    "# Feel free to expand the list and pick your favorite\n",
    "books = { \"Alice's Adventures in Wonderland\": 11  , # by Lewis Carroll, 160 kb\n",
    "          \"The Complete Poetical Works of Edgar Allan Poe\": 10031, #by Edgar Allan Poe, 400 kb\n",
    "          \"The Hound of the Baskervilles\":    2852, # by Sir Conan Doyle, 340 kb\n",
    "          \"The King James Bible\":             10,   # by King James, 4.3 Mb\n",
    "          \"The Complete Works of William Shakespeare\": 100 #by William Shakespeare, 5.5 Mb\n",
    "        }\n",
    "\n",
    "def bookSelection(bookTitle):\n",
    "    bookId = books[bookTitle]\n",
    "    #\n",
    "    print( \"Loading text from Project Gutenberg URL...\" )\n",
    "    import urllib3\n",
    "    http = urllib3.PoolManager()\n",
    "    url = 'https://www.gutenberg.org/cache/epub/%s/pg%s.txt' % (bookId, bookId)\n",
    "    request = http.request('GET', url)\n",
    "    #\n",
    "    global book\n",
    "    book = request.data\n",
    "    print( \"Request done with %d bytes...\" % len(book))\n",
    "    #Converts from bytes to string\n",
    "    book = book.decode(\"utf-8\") \n",
    "    return\n",
    "\n",
    "interact(bookSelection, bookTitle=books.keys() );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words, with repetition:     62955\n",
      "Total number of words, without repetition:  5833\n"
     ]
    }
   ],
   "source": [
    "import re #Rational expressions\n",
    "words = re.split('[^A-Za-z]+', book.lower())\n",
    "words = [w for w in words if w!=''] # Remove empty strings\n",
    "\n",
    "# Computes a dictionary where keys are words\n",
    "#  and values are the number of occurrences.\n",
    "# Output is sorted\n",
    "def generate1gram():\n",
    "    gram = dict()\n",
    "    \n",
    "    # Populate 1-gram dictionary\n",
    "    for i in range(len(words)-1):\n",
    "        key = words[i]\n",
    "        if gram.get(key) is None:\n",
    "            gram[key] = 1\n",
    "        else:\n",
    "            gram[key] += 1\n",
    "    \n",
    "    #Warning! sorted forms a list\n",
    "    gram = sorted(gram.items(), key=lambda x:-x[1])\n",
    "    \n",
    "    return dict(gram)\n",
    "\n",
    "gram1 = generate1gram()\n",
    "\n",
    "# Print length of list\n",
    "print( \"Total number of words, with repetition:    \", len(words) )\n",
    "print( \"Total number of words, without repetition: \", len(gram1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Autocompletion avec des 1-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 1:\n",
    "Ecire une fonction findLastWord, dont l'entrée et la sortie sont des objets de type string. Etant donné une chaine de caractères, cette fonction doit isoler le dernier mot comme suit:\n",
    "- transformer le tout en lettres minuscules\n",
    "- enlever les espaces de fin\n",
    "- trouver le dernier espace et isoler le dernier mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6978e4f7d1c740f49aac7214fc962726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Input:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2ec4b7023a42dd9a37212b10e73446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b6b58f612d4eca80278a7f40cdf199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2ec4b7023a42dd9a37212b10e73446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1913f6997dc04148b0545c6622b409f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Last word:'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2ec4b7023a42dd9a37212b10e73446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b16c6a25345439d98a74764ee786b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Autocomplete suggestion:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2ec4b7023a42dd9a37212b10e73446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bff62867e4f42e98e255f79f047fb7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2ec4b7023a42dd9a37212b10e73446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Information labels\n",
    "infoLabel1 = widgets.Label(value=\"Input:\")\n",
    "infoLabel2 = widgets.Label(value=\"Last word:\")\n",
    "infoLabel3 = widgets.Label(value=\"Autocomplete suggestion:\")\n",
    "#Input area\n",
    "inputArea = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Type something',\n",
    "    description='',\n",
    "    disabled=False\n",
    ")\n",
    "# Output labels\n",
    "outputLastWord = widgets.Label(value='')\n",
    "outputLabel = widgets.Label(value='')\n",
    "output = widgets.Output()\n",
    "\n",
    "def findLastWord(str):\n",
    "    #TODO\n",
    "    return \"\"\n",
    "\n",
    "def onChange(change):\n",
    "    with output:\n",
    "        lastWord = findLastWord(change.new)\n",
    "        outputLastWord.value = lastWord\n",
    "        #\n",
    "        #Either the last word exists in the dictionary and then nothing to do\n",
    "        possibleWords = [ (w,x) for (w,x) in gram1.items() if w.startswith(lastWord)]\n",
    "        outputLabel.value = ''.join( [ (w+'(%d) ')%x for (w,x) in possibleWords ] )\n",
    "\n",
    "# Sets a callback upon the change of the TextArea's content\n",
    "inputArea.observe(onChange, 'value')\n",
    "\n",
    "display( infoLabel1, output)\n",
    "display( inputArea, output)\n",
    "display( widgets.HBox([infoLabel2, outputLastWord]), output)\n",
    "display( infoLabel3, output)\n",
    "display( outputLabel, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Predire le mot suivant: 2-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 2:\n",
    " - Adapter la fonction précédente generate1gram et écrire la fonction generate2gram qui retourne un dictionnaire dont les clés sont les paires de mots et les valeurs le nombre d'occurences\n",
    " - Ecrire une fonction predictNextWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes a dictionary where keys are all pairs of words\n",
    "#  and values are the number of occurrences.\n",
    "# Output is sorted\n",
    "def generate2gram():\n",
    "    # TODO    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-476cbe831b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgram2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate2gram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgram2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "gram2 = generate2gram()\n",
    "print( [(w,x) for (w,x) in gram2.items() if x>50] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a813c56d5a43e9bf6a855dae88205c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Input:'), Textarea(value='', placeholder='Type something')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5232afd056a44f6b15a50a44fbc32f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0733585449452f9f8eb1cf5f6041e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Autocomplete suggestions:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5232afd056a44f6b15a50a44fbc32f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09abd63d90834fbd8e7c216b903a4dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5232afd056a44f6b15a50a44fbc32f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08622157d2546c98f3edace79aa1e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Suggestion from word prediction:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5232afd056a44f6b15a50a44fbc32f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0417039b60ca4ce6a5688389aff54659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5232afd056a44f6b15a50a44fbc32f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Information labels\n",
    "infoLabel1 = widgets.Label(value=\"Input:\")\n",
    "infoLabel2 = widgets.Label(value=\"Autocomplete suggestions:\")\n",
    "infoLabel3 = widgets.Label(value=\"Suggestion from word prediction:\")\n",
    "#Input area\n",
    "inputArea = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Type something',\n",
    "    description='',\n",
    "    disabled=False\n",
    ")\n",
    "# Output labels\n",
    "outputAutocomplete = widgets.Label(value='')\n",
    "outputPrediction = widgets.Label(value='')\n",
    "output = widgets.Output()\n",
    "\n",
    "def onChange(change):\n",
    "    with output:\n",
    "        lastWord = findLastWord( change.new )\n",
    "        #\n",
    "        # Autocomplete as before\n",
    "        possibleWords = [ (w,x) for (w,x) in gram1.items() if w.startswith(lastWord)]\n",
    "        outputAutocomplete.value = ''.join( [ w+'(%d) '%x for (w,x) in possibleWords ] )\n",
    "        #\n",
    "        # Prediction\n",
    "        # Either the last word does not exist in the dictionary (or equivalently the 1-gram) and then nothing to do\n",
    "        if lastWord not in [w for (w,x) in possibleWords]:\n",
    "            outputPrediction.value = ''\n",
    "        # or the last word allows to predict the next\n",
    "        else:\n",
    "            possiblePairs = predictNextWord(lastWord)\n",
    "            outputPrediction.value = ''.join( [ (p[1]+'(%d) ') % x for (p,x) in possiblePairs ] )\n",
    "        \n",
    "def predictNextWord(str):\n",
    "    return \"\"\n",
    "\n",
    "# Sets a callback upon the change of the TextArea's content\n",
    "inputArea.observe(onChange, 'value')\n",
    "\n",
    "display( widgets.HBox( [infoLabel1, inputArea] ) , output)\n",
    "display( infoLabel2, output)\n",
    "display( outputAutocomplete, output)\n",
    "display( infoLabel3, output )\n",
    "display( outputPrediction, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. N-Grams (tri-grams and more...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, nous généralisons l'approche par chaines de Markov en prédisant le mot suivant à partir de plusieurs mots précédents. Pour cela, nous devons construire des Ngrams c'est-à-dire un dictionnaire de N-tuples de mots, en comptant les occurences.\n",
    "\n",
    "Exercice 3:\n",
    "1. Ecrire une fonction generateNgram\n",
    "2. Comprendre les lignes de code suivantes\n",
    "3. Remplir la fonction generate qui prend en entrée une chaine string et échantillonne un nouveau mot par prédiction de mot\n",
    "4. Ecrire une boucle qui commence par une chaine vide et génère le mot suivant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNgram(n=1):\n",
    "    return dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "gram5 = generateNgram(5)\n",
    "print( [(w,x) for (w,x) in gram5.items() if x>10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Ngrams for N from 1 to  4\n"
     ]
    }
   ],
   "source": [
    "maxLag = 5\n",
    "Ngrams = []\n",
    "for i in range(1,maxLag):\n",
    "    Ngrams.append( generateNgram(i))\n",
    "Ngrams.reverse() #Reverse order so that we start by Ngrams for N being the largest\n",
    "print( \"Generated Ngrams for N from 1 to \", len(Ngrams) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLastWords(str, count=1):\n",
    "    if count<= 0:\n",
    "        return []\n",
    "    str = str.lower()\n",
    "    str = str.rstrip()\n",
    "    #\n",
    "    lastWordIndex = str.rfind( ' ', 0, len(str))\n",
    "    lastWord = ''\n",
    "    if lastWordIndex == -1:\n",
    "        return [str]\n",
    "    else:\n",
    "        rec = findLastWords(str[:lastWordIndex], count-1)\n",
    "        rec.append( str[(lastWordIndex+1):] )\n",
    "        return rec\n",
    "\n",
    "# Predict the next word using all N-grams starting from the maximal lag\n",
    "def predictMaxLag(str):\n",
    "    for gram in Ngrams:\n",
    "        choice = [ (w,x) for (w,x) in gram.items() if w[:-1] == tuple( str[(len(str)-len(w)+1):] )]\n",
    "        if choice != []:\n",
    "            return choice\n",
    "    return []\n",
    "\n",
    "import random\n",
    "def weighted_choice(choice):\n",
    "   total = sum(w for c, w in choice)\n",
    "   r = random.uniform(0, total)\n",
    "   upto = 0\n",
    "   for c, w in choice:\n",
    "      if upto + w > r:\n",
    "         return c\n",
    "      upto += w\n",
    "    \n",
    "    \n",
    "def generate(str):\n",
    "    # TODO\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
